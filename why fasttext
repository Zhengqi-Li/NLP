FastText词向量与word2vec对比
本节来源于博客：fasttext
FastText= word2vec中 cbow + h-softmax的灵活使用

灵活体现在两个方面：

模型的输出层：word2vec的输出层，对应的是每一个term，计算某term的概率最大；而fasttext的输出层对应的是 分类的label。不过不管输出层对应的是什么内容，起对应的vector都不会被保留和使用；
模型的输入层：word2vec的输出层，是 context window 内的term；而fasttext 对应的整个sentence的内容，包括term，也包括 n-gram的内容；
两者本质的不同，体现在 h-softmax的使用。
Wordvec的目的是得到词向量，该词向量 最终是在输入层得到，输出层对应的 h-softmax 也会生成一系列的向量，但最终都被抛弃，不会使用。
fasttext则充分利用了h-softmax的分类功能，遍历分类树的所有叶节点，找到概率最大的label（一个或者N个）
--------------------- 
作者：悟乙己 
来源：CSDN 
原文：https://blog.csdn.net/sinat_26917383/article/details/54850933 
版权声明：本文为博主原创文章，转载请附上博文链接！
